# -*- coding: utf-8 -*-
"""Data Science II - Programming Assignment 3

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xK7wgY_eWI_dnms4U6RJJw9_Z6D9Y8p-

# Initial Setup
"""

!pip install -q pyspark

!wget -q 'https://drive.google.com/uc?export=download&id=1wAdLRbT_YgWJ1XRl39JM-lKwJpewdwyM' -O 'Sample.txt'

from pyspark import SparkContext, SparkConf
from pyspark.sql import SparkSession
import string
conf = SparkConf().setAppName('SparkWordCount')
sc = SparkContext.getOrCreate(conf = conf)

sqlContext = SparkSession.builder\
        .master("local")\
        .appName("Colab")\
        .config('spark.ui.port', '4050')\
        .getOrCreate()

"""
$~$

---



# Counting First Letters"""

def first_letter_filter(line):
    punc = set(string.punctuation)
    numbers = ["1", "2", "3", "4", "5", "6", "7", "8", "9", "0"]
    words = line.split()
    letter_list = []
    for word in words:
        for character in word:
          if character not in numbers and character not in punc:
            letter_list.append(character.lower())
            break
    return letter_list

input_file = sc.textFile('Sample.txt')

counts = input_file.flatMap(lambda line: first_letter_filter(line)).map(lambda word: (word, 1)) \
                 .reduceByKey(lambda a, b: a + b).sortByKey()
countsDF = sqlContext.createDataFrame(counts) \
            .withColumnRenamed('_1','Letter').withColumnRenamed('_2','Count')

countsDF.toPandas().to_csv('counts.csv', index=False)

countsDF.show(n=26)