# -*- coding: utf-8 -*-
"""Data Science II - Programming Assignment 2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NL34KO1V3uq3V9QavA7iffGRhmiltPmd

# Initial Setup
"""

!pip install -q pyspark

!wget -q 'https://drive.google.com/uc?export=download&id=1wAdLRbT_YgWJ1XRl39JM-lKwJpewdwyM' -O 'Sample.txt'

from pyspark import SparkContext, SparkConf
from pyspark.sql import SparkSession

conf = SparkConf().setAppName('SparkWordCount')
sc = SparkContext.getOrCreate(conf = conf)

sqlContext = SparkSession.builder\
        .master("local")\
        .appName("Colab")\
        .config('spark.ui.port', '4050')\
        .getOrCreate()

"""
$~$

---



# Counting 6-Word Sequences"""

sequence_length = 6

def sequence_length_filter(line, n = sequence_length):
    words = line.split()
    sequence_list = []
    for i in range(len(words)-(n-1)):
      sequence = ' '.join([words[i] for i in range(i, i+n)])
      sequence_list.append(sequence)
    return sequence_list

input_file = sc.textFile('Sample.txt')

counts = input_file.flatMap(lambda line: sequence_length_filter(line)).map(lambda word: (word, 1)) \
                 .reduceByKey(lambda a, b: a + b)


countsDF = sqlContext.createDataFrame(counts) \
            .withColumnRenamed('_1','Word').withColumnRenamed('_2','Count')

countsDF.toPandas().to_csv('counts.csv', index=False)

countsDF.show()